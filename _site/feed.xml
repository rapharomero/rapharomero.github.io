<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Raphaël's research website</title>
    <description></description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 24 Feb 2022 09:35:44 -0500</pubDate>
    <lastBuildDate>Thu, 24 Feb 2022 09:35:44 -0500</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>A visualization of latent space distance models for Graphs</title>
        <description>&lt;!--more--&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Latent space distance models for graphs form a broad class of statistical models for graph. In what follows we give a visual explanation of the mechanisms that allow these models to disantangle different effects in the network generation process.&lt;/p&gt;

&lt;h1 id=&quot;latent-space-models-for-graphs-lsm&quot;&gt;Latent space models for graphs (LSM)&lt;/h1&gt;

&lt;p&gt;$\newcommand{\Zcal}{\mathcal{Z}}$ Given a graph $G=(U,E)$ where $U$ is a set of nodes and $E\subset U\times U$ is the set of edges of $G$, a LSM supposes for each node $i\in U$ the existence of an underlying latent representation $z_{i}$ in a metric space $\Zcal$. We denote by $y_{ij}$ the (binary) indicator that the edge $ij$ is in $E$.&lt;/p&gt;

&lt;p&gt;Then, supposed that the edges $ij$ in the network are independently generated by a Bernoulli distributions $Bern(\theta_{ij})$, such that: $$\theta_{ij} = f(z_i, z_j)$$ for a certain similarity function $f$.&lt;/p&gt;

&lt;p&gt;Examples of Latent Space models include the stochastic block model, where the embeddings are discrete, the graphon model &lt;a class=&quot;citation&quot; href=&quot;#Lovsz2012LargeNA&quot;&gt;(Lovász, 2012)&lt;/a&gt;, and the Latent space distance model introduced in &lt;a class=&quot;citation&quot; href=&quot;#Hoff2002&quot;&gt;(Hoff et al., 2002)&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;latent-space-distance-models-lsdm&quot;&gt;Latent space distance models (LSDM)&lt;/h1&gt;

&lt;p&gt;Here we focus on the generic latent space distance models, presented in &lt;a class=&quot;citation&quot; href=&quot;#Hoff2002&quot;&gt;(Hoff et al., 2002)&lt;/a&gt;. Those are such that the similarity function is composed by a logit passed through an activation function $h$ (Usually the sigmoid function):&lt;/p&gt;

&lt;p&gt;$$a_{ij} \sim Bernoulli(\theta_{ij}) $$
 $$\theta_{ij} = h(2\gamma +\alpha_i + \alpha_j+  \lambda^Tx_{ij} - d(z_i,z_j))$$&lt;/p&gt;

&lt;p&gt;Where $\alpha_i$ and $\alpha_j$ &lt;em&gt;sociality&lt;/em&gt; parameters, $x_{ij}$ are predefined edge features, $\gamma$ is a bias parameter and $d$ is a distance, such as the euclidean distance.&lt;/p&gt;

&lt;!-- While using a similarity measure that is not a distance can also lead to interesting models, here we suppose that $d$ is the euclidean distance --&gt;

&lt;h3 id=&quot;deterministic-version-of-the-random-graphs-above&quot;&gt;Deterministic version of the random graphs above.&lt;/h3&gt;

&lt;p&gt;In order to geometrically explain how LSDMs disantangle, a possible approach is to make the (random) edge Bernoulli random variables, deterministic, by changing the link function. Indeed the sigmoid function is a smooth version of a non-continuous function, the Heaviside step function, given by $h(x) = \mathbb{1}_{{x&amp;gt;0}}$. This one yields an activation equal to 1 for positive inputs and 0 for negative inputs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/asserts/img/sigmoid_vs_heaviside.png&quot; alt=&quot;Heaviside&quot; /&gt; &lt;em&gt;The heaviside function in red, and the sigmoid function in green&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The deterministic graph is given by the following link indicators:&lt;/p&gt;

&lt;p&gt;$\newcommand{\ind}{\mathbb{1}}$&lt;/p&gt;

&lt;p&gt;$$
y_{ij} = \ind_{ d(z_i,z_j) \leq 2\gamma +\alpha_i + \alpha_j+  \lambda^Tx_{ij}}
$$&lt;/p&gt;

&lt;p&gt;This one has a natural visual interpretation, as shown in the following image.&lt;/p&gt;

&lt;p&gt;As can be seen, each embedding $z_i$ is endowed with a disk $D_i$ of radius $\alpha_i+\gamma$ such that the minimum distance between $D_i$ and $D_j$ in order for the nodes to connect is $\lambda^T x_{ij}$. If a given node has a large disk, it will naturally form more connections, independent on the position of the disk center.&lt;/p&gt;

&lt;p&gt;Moreover the prior similarity between nodes $i$ and $j$ is high, then the disk need not be too close for the connection to form. As a consequence, the embeddings will not encode the prior information contained in the term $\lambda^T x_{ij}$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/asserts/img/cne_deg1.png&quot; alt=&quot;CNE-DEG&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;Lovsz2012LargeNA&quot;&gt;Lovász, L. M. (2012). Large Networks and Graph Limits. &lt;i&gt;Colloquium Publications&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Hoff2002&quot;&gt;Hoff, P. D., Raftery, A. E., &amp;amp; Handcock, M. S. (2002). Latent space approaches to social network analysis. &lt;i&gt;Journal of the American Statistical Association&lt;/i&gt;, &lt;i&gt;97&lt;/i&gt;(460), 1090–1098. https://doi.org/10.1198/016214502388618906&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;
</description>
        <pubDate>Tue, 01 Feb 2022 00:00:00 -0500</pubDate>
        <link>/articles/22/latent-space-viz</link>
        <guid isPermaLink="true">/articles/22/latent-space-viz</guid>
        
        
      </item>
    
      <item>
        <title>Conditional Network Embedding, a Latent Space Distance perspective</title>
        <description>&lt;!--more--&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Conditional Network Embedding (CNE) &lt;a class=&quot;citation&quot; href=&quot;#KangLB19&quot;&gt;(Kang et al., 2019)&lt;/a&gt; is a node embedding method for graphs that has been successfully applied to visualization and prediction. It allows the user to generate node embeddings that respect the network structure, while factoring out prior knowledge known in advance. Applications of this include visualizing the nodes in a network without representing undesired effect, such as for instance having the high degree nodes concentrated in the center of the embedding space. The resulting embeddings can also be used to predict links while controlling the influence of sensitive node attributes on the predictions. This has great interest in producing fair link prediction on social networks, such as in &lt;a class=&quot;citation&quot; href=&quot;#buyl20a&quot;&gt;(Buyl &amp;amp; De Bie, 2020)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In what follows we aim to give a comprehensive view of the underlying mechanism that make CNE good at producing embeddings that factor out prior information.&lt;/p&gt;

&lt;!--

In what follows we express the Conditional Network Embeddings model as a
statistical model for which the parameter space is the cartesian product
of the space of embedding matrices and regression parameters w.r.t. edge
features \$\$f_{ij}\$\$. --&gt;

&lt;h1 id=&quot;conditional-network-embedding&quot;&gt;Conditional network embedding&lt;/h1&gt;

&lt;p&gt;Conditional Network Embedding is a graph embedding method.&lt;/p&gt;

&lt;p&gt;Given an undirected graph $G=(U,E)$ where $U$ is the set of nodes and $E\subset U\times U$ is the set of nodes it yields a mapping from the set of nodes to a $d$-dimensional space:&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}
CNE \colon U &amp;amp;\rightarrow &amp;amp; \mathbb{R}^d \\ u &amp;amp;\mapsto &amp;amp; z_u &lt;br /&gt;
\end{aligned}
$$&lt;/p&gt;

&lt;h1 id=&quot;factoring-out-prior-information-in-embeddings&quot;&gt;Factoring out prior information in embeddings&lt;/h1&gt;

&lt;p&gt;$\newcommand{\norm}[1]{\vert \vert #1 \vert \vert }$ In CNE, we suppose that we have encoded our prior expectations about an observed graph $\hat{G}$ into a MaxEnt distribution(see &lt;a href=&quot;//articles/20/maxent&quot;&gt;my post about Maxent&lt;/a&gt; or the paper &lt;a class=&quot;citation&quot; href=&quot;#debie2010maximum&quot;&gt;(Bie, 2010)&lt;/a&gt;). Moreover, we suppose that each node $i \in U$ is represented by an (unknown) embedding vector $z_i \in \mathbb{R}^d$, and that for two nodes $i \neq j$, their connection only depends on the embedding through the euclidean distance between their embeddings $d_{ij} = \norm{z_i-z_j}$.&lt;/p&gt;

&lt;p&gt;Based on that, CNE uses Bayes’ rule to define the link probability conditioned on the MaxEnt distribution:&lt;/p&gt;

&lt;p&gt;$$
P_{ij}(a_{ij}|z_i, z_j)= \frac{
\mathcal{N}_{+}(d_{ij} | s(a_{ij}))
P_{ij}(a_{i,j})
}{
\sum\limits_{a \in {0,1}}
\mathcal{N}_{+}(d_{ij} | s(a))
P_{ij}(a)
}
$$&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$d_{ij} = \vert\vert z_i-z_j \vert\vert$ is the euclidean distance between embeddings $z_i$ and $z_j$.&lt;/li&gt;
  &lt;li&gt;$\mathcal{N}_{+}(d\vert s(a))$ denotes a half normal density with spread parameter s(a).&lt;/li&gt;
  &lt;li&gt;$s$ is a spread function such that $s_0=s(0)&amp;gt;s(1)=s_1$&lt;/li&gt;
  &lt;li&gt;$P_{ij}(a)$ is the MaxEnt prior Bernoulli distribution&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thus, CNE postulates a distribution over the distance between embeddings, such that the distances between embeddings of non-edges are more spread around 0 than for edges.&lt;/p&gt;

&lt;p&gt;Finally, the probability of full graph $G$ is defined as the product of the independent link probabilities:&lt;/p&gt;

&lt;p&gt;$$
P(G\vert Z) =\prod_{i\neq j}P_{ij}(a_{ij}|z_i, z_j)
$$&lt;/p&gt;

&lt;h3 id=&quot;retrieving-the-link-bernoulli-probabilities&quot;&gt;Retrieving the link Bernoulli probabilities&lt;/h3&gt;

&lt;p&gt;As seen before, the full likelihood of a graph under the CNE model can be written as product of independent probabilities, one for each node pair. As the link indicator $a_{ij}$ between each node pair $ij$ is a Bernoulli random variable, one can transform the expression in order to retrieve the Bernoulli probabilities.&lt;/p&gt;

&lt;p&gt;Indeed, it can be shown that the edge link probabilties can be rewritten as: $$P_{ij}(a_{ij} \vert z_i, z_j) =  Q_{ij}^{a_{ij}}(1-Q_{ij})^{(1-a_{ij})}$$&lt;/p&gt;

&lt;p&gt;Where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$Q_{ij} = \sigma \left(\alpha + \lambda^Tf_{ij} - \beta.\frac{d_{ij}^2}{2} \right)$&lt;/li&gt;
  &lt;li&gt;$\alpha=\log(\frac{s_1}{s_0})$ is a non-negative constant.&lt;/li&gt;
  &lt;li&gt;$\beta=(\frac{1}{s_1^2} - \frac{1}{s_0^2}) \geq 0$ is a scaling constant.&lt;/li&gt;
  &lt;li&gt;$\sigma$ still denotes the sigmoid function&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;proof&quot;&gt;Proof&lt;/h4&gt;

&lt;p&gt;In order to retrieve this form, we first recall the form of the Half-Normal distribution:&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}
p_{\mathcal{N}_{+}(.\vert s)}(d) = \sqrt{\frac{2}{\pi s^2}} exp(- \frac{d^2}{2 d^2})
\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;Moreover, the MaxEnt prior distribution writes:&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}
P_{ij}(a_{ij})=\frac{exp(\lambda^Tf_{ij}(G))}{1+exp(\lambda^Tf_{ij}(G))}
\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;Since $P_{ij}(a_{ij} \vert z_i, z_j)$ is a Bernoulli probability, we have $Q_{ij} = P_{ij}(1 \vert z_i, z_j)$&lt;/p&gt;

&lt;p&gt;Injecting $a_{ij}=1$ in the expression of $P_{ij}(a_{ij} \vert z_i, z_j)$ and simplifying gives:&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}Q_{ij}=&amp;amp; \frac{
\sqrt{\frac{2}{\pi s_1^2}}
exp(- \frac{d_{ij}^2}{2 s_1^2} + \lambda^Tf_{ij})
}{
\sqrt{\frac{2}{\pi s_1^2}}
\exp(- \frac{d_{ij}^2}{2 s_1^2} + \lambda^Tf_{ij}) +
\sqrt{\frac{2}{\pi s_0^2}}
\exp(- \frac{d_{ij}^2}{2 s_0^2})
} \\ = &amp;amp;
\frac{1}{
  1 +
\exp\left(- \frac{d_{ij}^2}{2}(\frac{1}{s_0^2} - \frac{1}{s_1^2}) - \lambda^Tf_{ij} - log(\frac{s_0}{s_1})\right)
} \\ =&amp;amp;
\sigma(\lambda^Tf_{ij} + log(\frac{s_0}{s_1}) - \frac{d_{ij}^2}{2}(\frac{1}{s_1^2} - \frac{1}{s_0^2})) &lt;br /&gt;
\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;where $\sigma:x \mapsto \frac{1}{1+exp(-x)}$ is the sigmoid function.&lt;/p&gt;

&lt;h3 id=&quot;connection-with-latent-space-models-for-graphs&quot;&gt;Connection with Latent space models for graphs&lt;/h3&gt;

&lt;p&gt;As we see, the independent link logits logit in CNE are given by subtracting the scaled distance between embeddings to prior terms and a constant bias: $$logit(Q_{ij})=C+ \lambda^Tf_{ij} - D . d_{ij}^2$$ where $C= log(\frac{s_0}{s_1})$ and $D=0.5*(\frac{1}{s_1^2} - \frac{1}{s_0^2})$&lt;/p&gt;

&lt;p&gt;(The logit is defined as the inverse of the sigmoid function: $\sigma(logit(p)) = logit(\sigma(p))=p$)&lt;/p&gt;

&lt;p&gt;Intuitively, the term $\lambda^Tf_{ij}$ encodes a prior similarity value between $i$ and $j$ that doesn’t need to be represented by a small distance between the embeddings $z_i$ and $z_j$.&lt;/p&gt;

&lt;p&gt;This type of statistical model has been studied in a variety of previous work, in the name of Latent Space Distance Models &lt;a class=&quot;citation&quot; href=&quot;#Hoff2002&quot;&gt;(Hoff et al., 2002; Turnbull &amp;amp; Hons, 2019; Ma et al., 2020)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The common principle of this type of method is use the latent distance between vector representations as sufficient statistics for the link indicator variable.&lt;/p&gt;

&lt;h1 id=&quot;example-with-the-degree-and-edge-features-as-prior&quot;&gt;Example with the degree and edge features as prior.&lt;/h1&gt;

&lt;p&gt;Here we given an example of CNE model where we retrieve the Bernoulli probabilities $Q_{ij}$ given some prior statistics.&lt;/p&gt;

&lt;p&gt;We consider a simple example of CNE, where the MaxEnt statistics used are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The degree of each node $i$: $f_i^{(degree)}(G) = \sum\limits_{j\in \cal{N}(i)} a_{ij}$ where $\cal{N}(i)$ is the set of neighbors of $i$. This leads to $n$ statistics at the graph level. For each edge $ij$ the corresponding edge-level statistics vector $f_{ij}$ are given by $[E_i^n \vert\vert E_j^n]$, where for each node $i$, $E_i^n$ is the n-dimensional one-hot encoding of the node $i$ and $\vert\vert$ represents the concatenation operation. Denoting $\alpha \in \mathbb{R}^{2n}$ the vector of coefficients associated to these degree statistics, the corresponding logit value is equal to $$\alpha^Tf_{ij}=\alpha_i + \alpha_j$$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Some edge-level features $x_{ij}$. We denote $\theta$ the associated coefficient and the logit values coming from it are equal to : $$\theta^T x_{ij}$$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So by stacking all these features, we get the following prior term:&lt;/p&gt;

&lt;p&gt;$$\lambda^Tf_{ij}=\alpha_i + \alpha_j + \theta^T x_{ij}$$&lt;/p&gt;

&lt;p&gt;The CNE Bernoulli probabilities are thus equal to:&lt;/p&gt;

&lt;p&gt;$$Q_{ij} = \sigma \left(C + \alpha_i + \alpha_j + \theta^T x_{ij} - D. d_{ij}^2 \right) $$&lt;/p&gt;

&lt;!--
# Visual explanation

In order to geometrically explain how CNE factors out prior knowledge, a possible approach is to imagine the (random) edges as Bernoulli random variables, to make them deterministic variables conditioned on the embeddings.

### Deterministic version of the random graphs above.

The sigmoid function is a smooth version of a non-continuous function, the Heaviside step function, given by $h(x) = \mathbb{1}_{\{x&gt;0\}}$.
This one yields an activation equal to 1 for positive inputs and 0 for negative inputs.

![Heaviside](/figures/sigmoid_vs_heaviside.png)
_The heaviside function in red, and the sigmoid function in green_

Let's consider a CNE model, where we use as constraints the degrees of each nodes, as well as other features.
The CNE expression looks like:


\$\$
Q_{ij} = \sigma \left(2 \gamma +\alpha_i + \alpha_j+ \theta^T x_{ij} - \vert\vert z_i-z_j\vert\vert^2 \right)
\$\$

In the deterministic CNE expression, the link indicators would then look like:

\$\$
a_{ij} =h\left(2\gamma +\alpha_i + \alpha_j+ \theta^Tx_{ij} - \vert\vert z_i-z_j\vert\vert \right)
\$\$

This has a natural visual interpretation, as shown in the following image
![CNE-DEG](/figures/cne_deg1.png)

As can be seen, each embedding $z_i$ is endowed with a disk $D_i$of radius $\alpha_i+\gamma$ such that the minimum distance between $D_i$ and $D_j$ in order for the nodes to connect is $\theta^T x_{ij}$.

If the prior similarity is high, the the disk need not be too close for the connection to form. As a consequence, the embeddings will not encode the prior information. --&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;KangLB19&quot;&gt;Kang, B., Lijffijt, J., &amp;amp; Bie, T. D. (2019). Conditional Network Embeddings. &lt;i&gt;7th International Conference on Learning Representations, ICLR 2019,
               New Orleans, LA, USA, May 6-9, 2019&lt;/i&gt;. https://openreview.net/forum?id=ryepUj0qtX&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;buyl20a&quot;&gt;Buyl, M., &amp;amp; De Bie, T. (2020). DeBayes: a Bayesian Method for Debiasing Network Embeddings. &lt;i&gt;Proceedings of the 37th International Conference on Machine Learning&lt;/i&gt;, &lt;i&gt;119&lt;/i&gt;, 1220–1229. https://proceedings.mlr.press/v119/buyl20a.html&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;debie2010maximum&quot;&gt;Bie, T. D. (2010). &lt;i&gt;Maximum entropy models and subjective interestingness: an application to tiles in binary databases&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Hoff2002&quot;&gt;Hoff, P. D., Raftery, A. E., &amp;amp; Handcock, M. S. (2002). Latent space approaches to social network analysis. &lt;i&gt;Journal of the American Statistical Association&lt;/i&gt;, &lt;i&gt;97&lt;/i&gt;(460), 1090–1098. https://doi.org/10.1198/016214502388618906&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Turnbull2019&quot;&gt;Turnbull, K. R., &amp;amp; Hons, M. (2019). &lt;i&gt;Advancements in Latent Space Network Modelling&lt;/i&gt;. &lt;i&gt;December&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;Ma2020a&quot;&gt;Ma, Z., Ma, Z., &amp;amp; Yuan, H. (2020). Universal latent space model fitting for large networks with edge covariates. &lt;i&gt;Journal of Machine Learning Research&lt;/i&gt;, &lt;i&gt;21&lt;/i&gt;, 1–67.&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;
</description>
        <pubDate>Tue, 01 Feb 2022 00:00:00 -0500</pubDate>
        <link>/articles/22/cne_latent</link>
        <guid isPermaLink="true">/articles/22/cne_latent</guid>
        
        
      </item>
    
      <item>
        <title>Maximum Entropy (MaxEnt) models for Graphs</title>
        <description>&lt;!--more--&gt;

&lt;p&gt;$\newcommand{\Gcal}{\mathcal{G}}$ $\newcommand{\R}{\mathbb{R}}$ $\newcommand{\Gcal}{\mathcal{G}}$ $\newcommand{\Gcal}{\mathcal{G}}$ $\newcommand{\Gcal}{\mathcal{G}}$ $\newcommand{\Gcal}{\mathcal{G}}$&lt;/p&gt;

&lt;p&gt;In this post, we explain Maximum Entropy models for graphs, as presented in previous work &lt;a class=&quot;citation&quot; href=&quot;#debie2010maximum&quot;&gt;(Bie, 2010)&lt;/a&gt; and &lt;a class=&quot;citation&quot; href=&quot;#adriaens&quot;&gt;(Adriaens et al., 2017)&lt;/a&gt;, and how they can be used to derive prior distributions on graphs.&lt;/p&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;Many real-world phenomena can be (at least partially) described in the form of networks. Examples include social networks, user behavior online, neurons in the brain, ecological networks etc…&lt;/p&gt;

&lt;p&gt;Before any real-world network is observed, the observer generally has prior expectations about the properties of this graph, depending on its nature.&lt;/p&gt;

&lt;p&gt;For instance, one might have an idea of the number of links, the number of links &lt;em&gt;per node&lt;/em&gt; (their degree).&lt;/p&gt;

&lt;p&gt;In a social network, one might have prior expectations about the number of links connecting any two communities. Indeed, the fact that people from the same community tend to connect more than from different ones is a fact commonly observed in real-world social networks and often quoted as &lt;em&gt;homophily&lt;/em&gt;.&lt;/p&gt;

&lt;h1 id=&quot;formalizing-prior-expectations&quot;&gt;Formalizing prior expectations&lt;/h1&gt;

&lt;h4 id=&quot;notations&quot;&gt;Notations&lt;/h4&gt;

&lt;p&gt;Let $U$ a set of nodes. A graph is a tuple $G=(U, E)$ where $E\subset U \times U$ is the set of edges of the graph. For a fixed set of nodes $U$, we denote by $\Gcal$ the set of possible undirected graphs connecting the nodes in $U$. Each graph $G\in\Gcal$ can be fully described by its adjacency matrix: $A=(a_{ij})\in \{0,1\}^{n^2}$, such that $a_{ij}=1$ if and only if the nodes $i$ and $j$ are connected. For each node $i \in U$, we denote $\mathcal{N}(i)$ its set of neighbors.&lt;/p&gt;

&lt;h4 id=&quot;prior-statistics&quot;&gt;Prior statistics&lt;/h4&gt;

&lt;p&gt;Prior expectations about a grpah can be expressed or modelled as &lt;em&gt;statistics&lt;/em&gt;, which are defined as measurable functions taking as input a graph and yielding a real number:&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}
f&amp;amp;: &amp;amp;G  &amp;amp;\mapsto&amp;amp; &amp;amp;f(G)  \\ &amp;amp;&amp;amp;\Gcal &amp;amp;\rightarrow&amp;amp; &amp;amp;\R&lt;br /&gt;
\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;Examples of such statistics include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The degree of each node $i$: $$f_i^{(degree)}(G) = \sum\limits_{j\in \cal{N}(i)} a_{ij}$$&lt;/li&gt;
  &lt;li&gt;The number of connections between two node subsets $W, W’ \subset U$: $$f_{W,W’}^{(block)}(G) = \sum\limits_{i,j \in W \times W’} a_{ij}$$&lt;/li&gt;
&lt;/ul&gt;

&lt;!--
\$\$
f: G\in \Gcal \mapsto f(G) \in \R*+
\Gcal \rightarrow \R*+
\$\$ --&gt;

&lt;h1 id=&quot;maximum-entropy-models&quot;&gt;Maximum Entropy models&lt;/h1&gt;

&lt;p&gt;Supposing that we encode our prior expectations into $K$ statistics $f_1,…,f_K$ where each $f_k$ is a real-valued graph function, then the maximum entropy principle can be used to convert those into a &lt;em&gt;prior distribution&lt;/em&gt; on the set of possible graphs.&lt;/p&gt;

&lt;h4 id=&quot;graph-distributions&quot;&gt;Graph distributions&lt;/h4&gt;

&lt;p&gt;A &lt;em&gt;graph distribution&lt;/em&gt; is a probability distribution defined on the set of graphs $\Gcal$. In other words, it can be identified witha function $P$ that gives for each graph $G \in \Gcal$ the likelihood $P(G)$ of observing this particular graph&lt;/p&gt;

&lt;h4 id=&quot;entropy-of-a-graph-distribution&quot;&gt;Entropy of a graph distribution.&lt;/h4&gt;

&lt;p&gt;The &lt;em&gt;entropy value&lt;/em&gt; of any distribution $P$ being defined as $$H(P) = -\sum_{G\in\Gcal} P(G)\log(P(G))$$&lt;/p&gt;

&lt;p&gt;This quantity measures the average amount of information provided by the observation of a graph, under the distribution $P$.&lt;/p&gt;

&lt;!-- Under this principle, we want to find a distribution on the set of possible graphs $\Gcal$, that has maximum entropy value, --&gt;

&lt;h4 id=&quot;expected-value-of-the-prior-statistics&quot;&gt;Expected value of the prior statistics&lt;/h4&gt;

&lt;p&gt;$\newcommand{\Ebb}{\mathbb{E}}$ For a given graph distribution $P$, and a graph statistic $f$, one can define the expectation of this graph statistic as: $$\Ebb[f(G)]= \sum_{G\in \Gcal} f(G)P(G)$$&lt;/p&gt;

&lt;h4 id=&quot;maximizing-the-entropy-under-statistics-based-constraints&quot;&gt;Maximizing the entropy under statistics-based constraints&lt;/h4&gt;

&lt;p&gt;Supposing that we encode our prior expectations into $K$ statistics $f_1,…,f_K$ where each $f_k$ is a real-valued graph function, then the maximum entropy principle can be used to derive a resulting &lt;em&gt;prior distribution&lt;/em&gt; on the set of possible graphs.&lt;/p&gt;

&lt;p&gt;While prior expectations about the graph are provided in the form of graph statistics value, we would like to define a distribution over the set of graphs, such that the expected value of the statistics under this distribtution are equal to the one that we expect. In other words we want to impose &lt;em&gt;soft constraints&lt;/em&gt; on the graph distribution.&lt;/p&gt;

&lt;p&gt;Namely, we want our distribution to satisfy for all $k=1,…,K$: $$\Ebb[f(G)]= c_k$$&lt;/p&gt;

&lt;p&gt;Where $c_k$ is our prior expectation value for the statistic $k$. Under these constraints, we use the Maximum Entropy principle to define a prior distribution over the set of graphs such that the obtained distribution &lt;strong&gt;provides as least information&lt;/strong&gt; as possible, in addition to satisfying the statistic constraints.&lt;/p&gt;

&lt;p&gt;Achieving this amounts in solving the Maximum Entropy constrained optimization problem:&lt;/p&gt;

&lt;!-- % \left\{ --&gt;

&lt;p&gt;$$
\begin{array}{cc}
\max\limits_{P} &amp;amp; H(P) \\ \text{such that}  &amp;amp;\Ebb[f(G)]= c_k , k=1,…,K\\ &amp;amp;\sum_{G\in\Gcal}P(G)=1
\end{array}
$$&lt;/p&gt;

&lt;!-- % \right./ --&gt;

&lt;p&gt;It can be shown that the maximum entropy distribution can be written, for a certain parameter vector $\lambda \in \mathbb{R}^K$ and each graph $G\in \mathcal{G}$:&lt;/p&gt;

&lt;p&gt;$$
P^*_{\lambda}(G) =
\frac{
\exp(\lambda^T f(G))
}{
\sum_{G \in \mathcal{G}}\exp(\lambda^T f(G))
}
$$&lt;/p&gt;

&lt;p&gt;Where $f(G)=(f_1(G), …, f_K(G))$ is the vector of graph statistics.&lt;/p&gt;

&lt;h4 id=&quot;link-with-maximum-likelihood-estimation&quot;&gt;Link with Maximum Likelihood Estimation&lt;/h4&gt;

&lt;p&gt;There is a strong connection between the above Maximum Entropy problem and Maximum Likelihood estimation. First we note that these two problems are distinct: while the first is a variational optimization problem (the optimization variable is the probability distribution $P$), the second is an simple convex optimization problem where the optimization variable is the parameter vector $\lambda$.&lt;/p&gt;

&lt;p&gt;Their common point is that they are dual problems from each other. Indeed, for any distribution $P$ the Lagrangian associated with the MaxEnt Problem writes:&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}
\mathcal{L}(P, \lambda)
=&amp;amp;-\sum\limits_{G \in \mathcal{G}} P(G) log(P(G))\\ &amp;amp;- \sum\limits_{k=1}^{K} \lambda_k (\sum\limits_{G \in \mathcal{G}} P(G)  f_k(G) -  c_k )
\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;$\newcommand{\Lcal}{\mathcal{L}}$ $\newcommand{\Ghat}{\hat{G}}$ $\newcommand{\Pstar}{P^*_{\lambda}}$&lt;/p&gt;

&lt;p&gt;In the context of statistics where we observe a graph $\Ghat$ and set $c_k=f_k(\Ghat)$ for all the statistics $k=1,…,K$, it can be easily shown that&lt;/p&gt;

&lt;p&gt;$$\Lcal(\Pstar, \lambda) = -\log(\Pstar(\Ghat)).$$ Hence the Lagrangian is exactly equal to the negative log-likelihood of the model.&lt;/p&gt;

&lt;h3 id=&quot;factorized-form&quot;&gt;Factorized form&lt;/h3&gt;

&lt;p&gt;A broad range of graph statistics can be decomposed as of edge-specific statistics, i.e.: $\newcommand{\fijk}{f_{ij}^{(k)}}$ $$f_k(G)= \sum\limits_{i \neq j} \fijk(a_{ij}),$$&lt;/p&gt;

&lt;p&gt;For instance, the degree of a node is equal to the sum of the corresponding row of the adjacency matrix, and the volume of interaction between two communities is the sum of the entries located in a block of the adjacency matrix.&lt;/p&gt;

&lt;p&gt;It can be shown that for these statistics the MaxEnt distribution factorizes over the set of edges. More precisely, in that case we can derive edge-specific statistic vectors, denoted $f_{ij}(G)$, such that:&lt;/p&gt;

&lt;p&gt;$$\Pstar(G)=\prod\limits_{i\neq j} P_{ij}(a_{ij})$$ Where for each edge $ij$, $P_{ij}$ is a Bernoulli probability with parameter $$\frac{1}{1+exp(-\lambda^T f_{i,j}(G))}$$ This expression allows to express the graph distribution as a joint distribution of independent edge-specific Bernoulli variables $a_{ij}$. Moreover, the Bernoulli probabilities for each edge are given by a linear logit $\lambda^T f_{i,j}(G)$, passed through the sigmoid function $\sigma :x\mapsto \frac{1}{1+exp(-x)}$.&lt;/p&gt;

&lt;h3 id=&quot;how-to-turn-prior-knowledge-statistics-into-a-maxent-distribution&quot;&gt;How to turn prior knowledge statistics into a MaxEnt distribution&lt;/h3&gt;

&lt;p&gt;In practice, such a distribution can used to extract prior information from an observed graph $\hat{G}$. We recall that the input of this procedure is a set of graph statistic functions, that each quantify an aspect of our expectation on the graph distribution. Based on this, one can apply the statistics $f_k$ to the observed graph, and use the obtained values To do this, one just needs to maximize the above likelihood of the observed graph with respect to the parameter vector $\lambda$:&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}
\max\limits_{\lambda\in \mathbb{R}^K} P(\hat{G}) &lt;br /&gt;
\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;It can be noted that this Maximum Likelihood problem can be solved using logistic regression. Indeed, for each each edge, we access a feature vector $f_{i,j}(\hat{G})$ use it to predict the presence of absence or link between nodes $i$ and $j$.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;We have seen how Maximum Entropy models for graph can be used to formalize prior knowledge about a graph, encoded as soft constraints.&lt;/p&gt;

&lt;p&gt;The resulting model has been widely studied in network science literature, under the name of P* (p-star) model, or Exponential random graph models. I&lt;/p&gt;

&lt;p&gt;The dyad-independent expression has served as the basis of Later work such as Conditional Network Embeddings &lt;a class=&quot;citation&quot; href=&quot;#KangLB19&quot;&gt;(Kang et al., 2019)&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;debie2010maximum&quot;&gt;Bie, T. D. (2010). &lt;i&gt;Maximum entropy models and subjective interestingness: an application to tiles in binary databases&lt;/i&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;adriaens&quot;&gt;Adriaens, F., Lijffijt, J., &amp;amp; De Bie, T. (2017). Subjectively interesting connecting trees. In M. Ceci, J. Hollmén, L. Todorovski, &amp;amp; C. Vens (Eds.), &lt;i&gt;Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2017, Skopje, Macedonia, September 18–22, 2017, Proceedings, Part II&lt;/i&gt; (Vol. 10535, Number 2, pp. 53–69). Springer International Publishing. http://dx.doi.org/10.1007/978-3-319-71246-8_4&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;KangLB19&quot;&gt;Kang, B., Lijffijt, J., &amp;amp; Bie, T. D. (2019). Conditional Network Embeddings. &lt;i&gt;7th International Conference on Learning Representations, ICLR 2019,
               New Orleans, LA, USA, May 6-9, 2019&lt;/i&gt;. https://openreview.net/forum?id=ryepUj0qtX&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;

&lt;!-- In this paragraph, we have seen how MaxEnt model allow us to encode prior knowledge into a graph distribution $P(G)$ and for a certain type of statistics this translates into a set of independent bernoulli variables with proabilities $P_{ij}(a_{ij})=\sigma(\lambda^Tf_{ij}(G))$.
Now we will see how, once we have derived such a MaxEnt distribution, we can use it to find embeddings conditional on this distribution.

\$\$
\$\$ --&gt;
</description>
        <pubDate>Thu, 01 Oct 2020 00:00:00 -0400</pubDate>
        <link>/articles/20/maxent</link>
        <guid isPermaLink="true">/articles/20/maxent</guid>
        
        
      </item>
    
      <item>
        <title>Edge Cases</title>
        <description>&lt;p&gt;Some edge cases and cautionary examples on using Markdown for writing content using this theme. In particular, list syntax can really knot things up.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h3 id=&quot;mathjax-improperly-parsing-greater-and-less-than-and-ampersands-inside-blocks&quot;&gt;Mathjax improperly parsing greater and less than and ampersands inside blocks&lt;/h3&gt;

&lt;p&gt;The mathjax HTML &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;head&amp;gt;&lt;/code&gt; scripts have been modified to properly render block style mathjax expressions inside a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$$ ... $$&lt;/code&gt; set of character pairs,
using the standard Kramdown parser. Some examples sent to me by Quxiaofeng are now parsing correctly, I believe.&lt;/p&gt;

&lt;p&gt;This code:&lt;/p&gt;

&lt;div class=&quot;language-latex highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;$$&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;
  D &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\cdots&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;$$&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;yields this:&lt;/p&gt;

&lt;p&gt;$$
D = \left(\begin{matrix}
  1 &amp;amp; -1 &amp;amp; &amp;amp; &amp;amp; &amp;amp; &lt;br /&gt;
  &amp;amp;    &amp;amp; \cdots &amp;amp;   &amp;amp; &lt;br /&gt;
  &amp;amp;    &amp;amp;        &amp;amp; 1 &amp;amp; -1
\end{matrix}
\right)
$$&lt;/p&gt;

&lt;p&gt;Other examples from the &lt;a href=&quot;http://latex.wikia.com/wiki/Matrix_environments&quot;&gt;wikia Tex reference&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;$$
\begin{matrix}
\alpha&amp;amp; \beta^{&lt;em&gt;}&lt;br /&gt;
\gamma^{&lt;/em&gt;}&amp;amp; \delta
\end{matrix}
$$&lt;/p&gt;

&lt;p&gt;$$
\begin{bmatrix}
\alpha&amp;amp; \beta^{&lt;em&gt;}&lt;br /&gt;
\gamma^{&lt;/em&gt;}&amp;amp; \delta
\end{bmatrix}
$$&lt;/p&gt;

&lt;p&gt;$$
\begin{Bmatrix}
\alpha&amp;amp; \beta^{&lt;em&gt;}&lt;br /&gt;
\gamma^{&lt;/em&gt;}&amp;amp; \delta
\end{Bmatrix}
$$&lt;/p&gt;

&lt;p&gt;$$
\begin{vmatrix}
\alpha&amp;amp; \beta^{&lt;em&gt;}&lt;br /&gt;
\gamma^{&lt;/em&gt;}&amp;amp; \delta
\end{vmatrix}
$$&lt;/p&gt;

&lt;p&gt;$$
\begin{Vmatrix}
\alpha&amp;amp; \beta^{&lt;em&gt;}&lt;br /&gt;
\gamma^{&lt;/em&gt;}&amp;amp; \delta
\end{Vmatrix}
$$&lt;/p&gt;

&lt;p&gt;$$
\begin{Vmatrix}
\alpha&amp;amp; \beta^{&lt;em&gt;}&lt;br /&gt;
\gamma^{&lt;/em&gt;}&amp;amp; \delta
\end{Vmatrix}
$$&lt;/p&gt;

&lt;p&gt;However, a problem still exists for inline matrix notation, from an example &lt;a href=&quot;https://en.wikibooks.org/wiki/LaTeX/Mathematics#Matrices_in_running_text&quot;&gt;here&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;A matrix in text must be set smaller: $$ \bigl(\begin{smallmatrix}a &amp;amp; b \\ c &amp;amp; d\end{smallmatrix} \bigr) $$ to not increase leading in a portion of text. The way this inline matrix is written is: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$$ \bigl(\begin{smallmatrix}a &amp;amp; b \\ c &amp;amp; d\end{smallmatrix} \bigr) $$&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;edge-case-1-from-quxiaofeng&quot;&gt;Edge Case 1 from Quxiaofeng:&lt;/h2&gt;

&lt;h3 id=&quot;no-blank-lines-between-markdown-list-items&quot;&gt;No blank lines between Markdown list items&lt;/h3&gt;

&lt;p&gt;The issue arises when sidenotes and marginnotes are put into list items.  As mentioned in the main documentation page, lists can be problematic not only for semantic clarity, but also because they can creating formatting issues. For example:&lt;/p&gt;

&lt;h3 id=&quot;related-algorithms&quot;&gt;Related algorithms&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Split Bregman iteration &lt;label for=&quot;1&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;1&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Goldstein, T. and Osher, S. (2009). The split Bregman method for l1-regularized problems. SIAM J. Img. Sci., 2:323-343. &lt;/span&gt;&lt;/li&gt;
  &lt;li&gt;Dykstra’s alternating projection algorithm &lt;label for=&quot;2&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;2&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Dykstra, R. L. (1983). An algorithm for restricted least squares regression. J. Amer. Statist. Assoc., 78(384):837-842. &lt;/span&gt;&lt;/li&gt;
  &lt;li&gt;Proximal point algorithm applied to the dual&lt;/li&gt;
  &lt;li&gt;Numerous applications in statistics and machine learning: lasso, gen. lasso, graphical lasso, (overlapping) group lasso, …&lt;/li&gt;
  &lt;li&gt;Embraces distributed computing for big data &lt;label for=&quot;3&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;3&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Boyd, S., Parikh, N., Chu, E., Peleato, B., and Eckstein, J. (2011). Distributed optimization and statistical learning via the alternating direction method of multipliers. Found. Trends Mach. learn., 3(1):1-122. &lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;why-this-matters&quot;&gt;Why this matters&lt;/h3&gt;

&lt;p&gt;Notice how the sidenotes display properly, but the fact that sidenotes have more display ‘volume’ than the list items themselves causes a horizontal mismatch between the sidenote item’s number and its corresponding list item.&lt;/p&gt;

&lt;p&gt;Please note that there must be &lt;em&gt;no blank lines between your list items&lt;/em&gt;. This is due to a really strange thing about the Jekyll Markdown engine I have never noticed before. If you have a list, and you put a blank line between the items like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  + list item 1

  + list item 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It will create an html tag structure like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;ul&amp;gt;
   &amp;lt;li&amp;gt;
      &amp;lt;p&amp;gt;list item 1&amp;lt;/p&amp;gt;
  &amp;lt;/li&amp;gt;
  &amp;lt;li&amp;gt;
      &amp;lt;p&amp;gt;list item 2&amp;lt;/p&amp;gt;
   &amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Which &lt;em&gt;totally&lt;/em&gt; goofs up the layout CSS.&lt;/p&gt;

&lt;p&gt;However, if your Markdown is this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    + list item 1
    + list item 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It will create a tag structure like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;ul&amp;gt;
   &amp;lt;li&amp;gt;list item 1&amp;lt;/li&amp;gt;
   &amp;lt;li&amp;gt;list item 2&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is the same content as above, with a blank line separating the list items. Notice how the sidenotes get squashed into the main content area:&lt;/p&gt;

&lt;h3 id=&quot;remarks-on-admm-version-2---one-blank-line-between-markdown-list-items&quot;&gt;Remarks on ADMM version 2 - &lt;strong&gt;one blank line&lt;/strong&gt; between Markdown list items&lt;/h3&gt;

&lt;p&gt;Related algorithms&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Split Bregman iteration &lt;label for=&quot;1&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;1&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Goldstein, T. and Osher, S. (2009). The split Bregman method for l1-regularized problems. SIAM J. Img. Sci., 2:323-343. &lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dykstra’s alternating projection algorithm &lt;label for=&quot;2&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;2&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Dykstra, R. L. (1983). An algorithm for restricted least squares regression. J. Amer. Statist. Assoc., 78(384):837-842. &lt;/span&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Proximal point algorithm applied to the dual&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Numerous applications in statistics and machine learning: lasso, gen. lasso, graphical lasso, (overlapping) group lasso, …
&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;liquid-tag-parsing-strangeness&quot;&gt;Liquid tag parsing strangeness&lt;/h3&gt;

&lt;p&gt;Example of the proper way to write an url inside a &lt;em&gt;Liquid&lt;/em&gt; full-width image tag.&lt;/p&gt;

&lt;p&gt;This code: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% fullwidth &quot;assets/img/rhino.png&quot; &quot;Tuftes pet rhino (via &amp;lt;a href=\&quot;//www.edwardtufte.com/tufte/\&quot;&amp;gt;Edward Tufte&amp;lt;/a&amp;gt;)&quot;  %}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;produces the following image with a title. Notice that I have had to escape the double quotes in the HTML with a backslash. Also, the example above leaves out the single quote in ‘Tufte’s” because of the topsy-turvy way that you have to escape the escapes in code sections that are used for illustrative purposes in this text. Bottom line is that there are occasionally some odd interactions between the Markdown parser, custom &lt;em&gt;Liquid&lt;/em&gt; tags and HTML.&lt;/p&gt;
&lt;figure class=&quot;fullwidth&quot;&gt;&lt;img src=&quot;/assets/img/rhino.png&quot; /&gt;&lt;figcaption&gt;Tufte&amp;#8217;s pet rhino (via &lt;a href=&quot;//www.edwardtufte.com/tufte/&quot;&gt;Edward Tufte&lt;/a&gt;)&lt;/figcaption&gt;&lt;/figure&gt;
</description>
        <pubDate>Mon, 13 Apr 2020 13:04:01 -0400</pubDate>
        <link>/articles/20/Edge-Cases</link>
        <guid isPermaLink="true">/articles/20/Edge-Cases</guid>
        
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Tufte-style Jekyll blog</title>
        <description>&lt;p&gt;&lt;span class=&quot;newthought&quot;&gt;The Tufte Jekyll theme&lt;/span&gt;  is an attempt to create a website design with the look and feel of Edward Tufte’s books and handouts. Tufte’s style is known for its extensive use of sidenotes, tight integration of graphics with text, and well-set typography.&lt;!--more--&gt; The idea for this project is essentially cribbed wholesale from Tufte and R Markdown’s Tufte Handout format&lt;label for=&quot;One&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;One&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;See &lt;a href=&quot;https://tufte-latex.github.io/tufte-latex/&quot;&gt;tufte-latex.github.io/tufte-latex/&lt;/a&gt; and &lt;a href=&quot;http://rmarkdown.rstudio.com/tufte_handout_format.html&quot;&gt;rmarkdown.rstudio.com/tufte_handout_format&lt;/a&gt; &lt;/span&gt; This page is an adaptation of the &lt;a href=&quot;http://rmarkdown.rstudio.com/examples/tufte-handout.pdf&quot;&gt;Tufte Handout PDF&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;jekyll-customizations&quot;&gt;Jekyll customizations&lt;/h2&gt;

&lt;p&gt;This Jekyll blog theme is based on the github repository by Edward Tufte &lt;a href=&quot;https://github.com/edwardtufte/tufte-css&quot;&gt;here&lt;/a&gt;, which was orginally created by Dave Leipmann, but is now labeled under Edward Tufte’s moniker. I borrowed freely from the Tufte-CSS repo and have transformed many of the typographic and page-structural features into a set of custom Liquid tags that make creating content using this style much easier than writing straight HTML. Essentially, if you know markdown, and mix in a few custom Liquid tags, you can be creating a website with this document style in short order.&lt;/p&gt;

&lt;p&gt;The remainder of this sample post is a self-documenting survey of the features of the Tufte-Jekyll theme. I have taken almost all of the sample content from the &lt;a href=&quot;https://github.com/edwardtufte/tufte-css&quot;&gt;Tufte-css&lt;/a&gt; repo and embedded it here to illustrate the parity in appearence between the two. The additional verbiage and commentary I have added is to document the custom &lt;em&gt;Liquid&lt;/em&gt; markup tags and other features that are bundled with this theme.&lt;/p&gt;

&lt;h3 id=&quot;the-sass-settings-file&quot;&gt;The SASS settings file&lt;/h3&gt;

&lt;p&gt;I have taken much of the actual &lt;em&gt;Tufte-css&lt;/em&gt; files and modified them as necessary to accomodate the needs inherent in creating a Jekyll theme that has additional writing aids such as the Liquid tags. I have also turned the CSS file into a &lt;a href=&quot;http://sass-lang.com&quot;&gt;SASS&lt;/a&gt; file (the .scss type).  This means that you can alter things like font choices, text color, background color, and underlining style by changing values in this file. When the Jekyll site is built using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jekyll build&lt;/code&gt; the settings in this file will be compiled into the customized CSS file that the site uses.&lt;/p&gt;

&lt;p&gt;This file looks like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/* This file contains all the constants for colors and font styles */

$body-font:   ETBembo, Palatino, &quot;Palatino Linotype&quot;, &quot;Palatino LT STD&quot;, &quot;Book Antiqua&quot;, Georgia, serif;
// Note that Gill Sans is the top of the stack and corresponds to what is used in Tufte's books
// However, it is not a free font, so if it is not present on the computer that is viewing the webpage
// The free Google 'Lato' font is used instead. It is similar.
$sans-font:  &quot;Gill Sans&quot;, &quot;Gill Sans MT&quot;, &quot;Lato&quot;, Calibri, sans-serif;
$code-font: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace;
$url-font: &quot;Lucida Console&quot;, &quot;Lucida Sans Typewriter&quot;, Monaco, &quot;Bitstream Vera Sans Mono&quot;, monospace;
$text-color: #111;
$bg-color: #fffff8;
$contrast-color: #a00000;
$border-color: #333333;
$link-style: color; // choices are 'color' or 'underline'. Default is color using $contrast-color set above
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Any of these values can be changed in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_sass/_settings.scss&lt;/code&gt; file before the site is built. The default values are the ones from &lt;em&gt;tufte-css&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;fundamentals&quot;&gt;Fundamentals&lt;/h2&gt;

&lt;h3 id=&quot;color&quot;&gt;Color&lt;/h3&gt;

&lt;p&gt;Although paper handouts obviously have a pure white background, the web is better served by the use of slightly off-white and off-black colors. I picked &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#fffff8&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#111111&lt;/code&gt; because they are nearly indistinguishable from their ‘pure’ cousins, but dial down the harsh contrast. Tufte’s books are a study in spare, minimalist design. In his book &lt;a href=&quot;http://www.edwardtufte.com/tufte/books_vdqi&quot;&gt;The Visual Display of Quantitative Information&lt;/a&gt;, he uses a red ink to add some visual punctuation to the buff colored paper and dark ink. In that spirit, links are styled using a similar red color.&lt;/p&gt;

&lt;h3 id=&quot;headings&quot;&gt;Headings&lt;/h3&gt;

&lt;p&gt;Tufte CSS uses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; for the document title, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt; with class &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;code&lt;/code&gt; for the document subtitle, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;h2&amp;gt;&lt;/code&gt; for section headings, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;h3&amp;gt;&lt;/code&gt; for low-level headings. More specific headings are not encouraged. If you feel the urge to reach for a heading of level 4 or greater, consider redesigning your document:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of &lt;em&gt;sentences&lt;/em&gt; which then cumulate sequentially into &lt;em&gt;paragraphs&lt;/em&gt;, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;cite&gt;&lt;a href=&quot;http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB&quot;&gt;http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;

&lt;p&gt;As a bonus, this excerpt regarding the use of headings provides an example of using block quotes. Markdown does not have a native &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;cite&amp;gt;&lt;/code&gt; shorthand, but real html can be sprinkled in with the Markdown text. In the previous example, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;cite&amp;gt;&lt;/code&gt; was preceded with a single return after the quotation itself. The previous blockquote was written in Markdown thusly:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-Liquid&quot;&gt;[It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of *sentences* which then cumulate sequentially into *paragraphs*, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize.
&amp;lt;cite&amp;gt;[http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB](http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB)&amp;lt;/cite&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;span class=&quot;newthought&quot;&gt;In his later books&lt;/span&gt; &lt;label for=&quot;two&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;two&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;&lt;a href=&quot;http://www.edwardtufte.com/tufte/books_be&quot;&gt;http://www.edwardtufte.com/tufte/books_be&lt;/a&gt; &lt;/span&gt;, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and sets the first few words of the sentence in small caps. To accomplish this using this style, enclose the sentence fragment you want styled with small caps in a custom Liquid tag called ‘newthought’ like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-Liquid&quot;&gt;{% newthought 'In his later books' %}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;text&quot;&gt;Text&lt;/h3&gt;

&lt;p&gt;In print, Tufte uses the proprietary Monotype Bembo&lt;label for=&quot;3&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;3&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;See Tufte’s comment in the &lt;a href=&quot;http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000Vt&quot;&gt;Tufte book fonts&lt;/a&gt; thread. &lt;/span&gt; font. A similar effect is achieved in digital formats with the now open-source ETBembo, which Tufte-Jekyll supplies with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@font-face&lt;/code&gt; reference to a .ttf file. Thanks to &lt;a href=&quot;https://github.com/daveliepmann/tufte-css/commit/0a810a7d5f4707941c6f9fe99a53ec41f50a5c00&quot;&gt;Linjie Ding&lt;/a&gt;, italicized text uses the ETBembo Italic font instead of mechanically skewing the characters. In case ETBembo somehow doesn’t work, Tufte CSS degrades gracefully to other serif fonts like Palatino and Georgia. Notice that Tufte CSS includes separate font files for &lt;strong&gt;bold&lt;/strong&gt; (strong) and &lt;em&gt;italic&lt;/em&gt; (emphasis), instead of relying on the browser to mechanically transform the text. This is typographic best practice. It’s also really important. Thus concludes my unnecessary use of em and strong for the purpose of example.&lt;/p&gt;

&lt;p&gt;Code snippets ape GitHub’s font selection using Microsoft’s &lt;a href=&quot;http://www.microsoft.com/typography/ClearTypeFonts.mspx&quot;&gt;&lt;em&gt;Consolas&lt;/em&gt;&lt;/a&gt; and the sans-serif font uses Tufte’s choice of Gill Sans. Since this is not a free font, and some systems will not have it installed, the free google font &lt;a href=&quot;https://www.google.com/fonts/specimen/Lato&quot;&gt;&lt;em&gt;Lato&lt;/em&gt;&lt;/a&gt; is designated as a fallback.&lt;/p&gt;

&lt;h2 id=&quot;epigraphs&quot;&gt;Epigraphs&lt;/h2&gt;

&lt;div class=&quot;epigraph&quot;&gt;&lt;blockquote&gt;&lt;p&gt;The English language . . . becomes ugly and inaccurate because our thoughts are foolish, but the slovenliness of our language makes it easier for us to have foolish thoughts.&lt;/p&gt;&lt;footer&gt;George Orwell, &lt;cite&gt; &quot;Politics and the English Language&quot; &lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;&lt;/div&gt;

&lt;div class=&quot;epigraph&quot;&gt;&lt;blockquote&gt;&lt;p&gt;For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled.&lt;/p&gt;&lt;footer&gt;Richard P. Feynman, &lt;cite&gt; “What Do You Care What Other People Think?” &lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;&lt;/div&gt;

&lt;p&gt;If you’d like to introduce your page or a section of your page with some quotes, use epigraphs. The two examples above show how they are styled. Epigraph elements are modeled after chapter epigraphs in Tufte’s books (particularly &lt;em&gt;Beautiful Evidence&lt;/em&gt;). The &lt;a href=&quot;https://github.com/edwardtufte/tufte-css&quot;&gt;Tufte-css&lt;/a&gt; gitub repository has detailed instructions on how to achieve this using HTML elements. As an easier alternative, the &lt;em&gt;Tufte-jekyll&lt;/em&gt; theme uses custom &lt;em&gt;Liquid tag&lt;/em&gt; pairs that allow the writer to embed elements such as epigraphs in the middle of the regular Markdown text being edited.&lt;/p&gt;

&lt;p&gt;In order to use an epigraph in a page or section, type this:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% epigraph 'text of citation' 'author of citation' 'citation source'  %}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;to produce this:&lt;/p&gt;

&lt;div class=&quot;epigraph&quot;&gt;&lt;blockquote&gt;&lt;p&gt;I do not paint things, I paint only the differences between things.&lt;/p&gt;&lt;footer&gt;Henri Matisse, &lt;cite&gt;Henri Matisse Dessins: thèmes et variations, 1943&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;&lt;/div&gt;

&lt;div class=&quot;epigraph&quot;&gt;&lt;blockquote&gt;&lt;p&gt; &quot;How did you go bankrupt?&quot; Two ways. Gradually, then suddenly.&lt;/p&gt;&lt;footer&gt;Ernest Hemingway, &lt;cite&gt; &quot;The Sun Also Rises&quot; &lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;&lt;/div&gt;

&lt;h3 id=&quot;lists&quot;&gt;Lists&lt;/h3&gt;

&lt;p&gt;Tufte points out that while lists have valid uses, they tend to promote ineffective writing habits due to their “lack of syntactic and intellectual discipline”. He is particularly critical of hierarchical and bullet-pointed lists. So before reaching for an HTML list element, ask yourself:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Does this list actually have to be represented using an HTML ul or ol element?&lt;/li&gt;
  &lt;li&gt;Would my idea be better expressed as sentences in paragraphs?&lt;/li&gt;
  &lt;li&gt;Is my message causally complex enough to warrant a flow diagram instead?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is but a small subset of a proper overview of the topic of lists in communication. A better way to understand Tufte’s thoughts on lists would be to read “The Cognitive Style of PowerPoint: Pitching Out Corrupts Within,” a chapter in Tufte’s book &lt;em&gt;Beautiful Evidence&lt;/em&gt;, excerpted at some length by Tufte himself &lt;a href=&quot;http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0002QF&quot;&gt;on his website&lt;/a&gt;. The whole piece is information-dense and therefore difficult to summarize. He speaks to web design specifically, but in terms of examples and principles rather than as a set of simple do-this, don’t-do-that prescriptions. It is well worth reading in full for that reason alone.&lt;/p&gt;

&lt;p&gt;For these reasons, Tufte CSS encourages caution before reaching for a list element, and by default removes the bullet points from unordered lists.&lt;/p&gt;

&lt;h2 id=&quot;figures&quot;&gt;Figures&lt;/h2&gt;

&lt;h3 id=&quot;margin-figures&quot;&gt;Margin Figures&lt;/h3&gt;

&lt;p&gt;&lt;label for=&quot;mf-id-1&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mf-id-1&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/rhino.png&quot; /&gt;&lt;br /&gt;F.J. Cole, “The History of Albrecht Dürer’s Rhinoceros in Zoological Literature,” &lt;em&gt;Science, Medicine, and History: Essays on the Evolution of Scientific Thought and Medical Practice&lt;/em&gt; (London, 1953), ed. E. Ashworth Underwood, 337-356. From page 71 of Edward Tufte’s &lt;em&gt;Visual Explanations&lt;/em&gt;.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Images and graphics play an integral role in Tufte’s work. To place figures in the margin, use the custom margin figure liquid tag included in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_plugins&lt;/code&gt; directory like so:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% marginfigure 'mf-id-whatever' 'assets/img/rhino.png' 'F.J. Cole, “The History of Albrecht Dürer’s Rhinoceros in Zoological Literature,” *Science, Medicine, and History: Essays on the Evolution of Scientific Thought and Medical Practice* (London, 1953), ed. E. Ashworth Underwood, 337-356. From page 71 of Edward Tufte’s *Visual Explanations*.'  %}&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Note that this tag has &lt;em&gt;three&lt;/em&gt; parameters. The first is an arbitrary id. This parameter can be named anything as long as it is unique to this post. The second parameter is the path to the image. And the final parameter is whatever caption you want to be displayed with the figure.  All parameters &lt;em&gt;must&lt;/em&gt; be enclosed in quotes for this simple liquid tag to work!&lt;/p&gt;

&lt;p&gt;In this example, the &lt;em&gt;Liquid&lt;/em&gt; marginfigure tag was inserted &lt;em&gt;before&lt;/em&gt; the paragraph so that it aligns with the beginning of the paragraph. On small screens, the image will collapse into a small symbol: &lt;span class=&quot;contrast &quot;&gt;⊕&lt;/span&gt; at the location it has been inserted in the manuscript. Clicking on it will open the image.&lt;/p&gt;

&lt;h3 id=&quot;full-width-figures&quot;&gt;Full Width Figures&lt;/h3&gt;

&lt;p&gt;If you need a full-width image or figure, another custom liquid tag is available to use. Oddly enough, it is named ‘fullwidth’, and this markup:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% fullwidth 'assets/img/napoleons-march.png' 'Napoleon's March *(Edward Tufte’s English translation)*'  %}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Yields this:&lt;/p&gt;

&lt;figure class=&quot;fullwidth&quot;&gt;&lt;img src=&quot;/assets/img/napoleons-march.png&quot; /&gt;&lt;figcaption&gt;Napoleon’s March &lt;em&gt;(Edward Tufte’s English translation)&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&quot;main-column-figures&quot;&gt;Main Column Figures&lt;/h3&gt;

&lt;p&gt;Besides margin and full width figures, you can of course also include figures constrained to the main column. Yes, you guessed it, a custom liquid tag rides to the rescue once again:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% maincolumn 'assets/img/export-imports.png' 'From Edward Tufte, *Visual Display of Quantitative Information*, page 92'  %}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;yields this:&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/exports-imports.png&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;From Edward Tufte, &lt;em&gt;Visual Display of Quantitative Information&lt;/em&gt;, page 92&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;sidenotes-and-margin-notes&quot;&gt;Sidenotes and Margin notes&lt;/h2&gt;

&lt;p&gt;One of the most prominent and distinctive features of Tufte’s style is the extensive use of sidenotes and margin notes. Perhaps you have noticed their use in this document already. You are very astute.&lt;/p&gt;

&lt;p&gt;There is a wide margin to provide ample room for sidenotes and small figures. There exists a slight semantic distinction between &lt;em&gt;sidenotes&lt;/em&gt; and &lt;em&gt;marginnotes&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;sidenotes&quot;&gt;Sidenotes&lt;/h3&gt;

&lt;p&gt;Sidenotes&lt;label for=&quot;sn-id-whatever&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;sn-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;This is a sidenote and &lt;em&gt;displays a superscript&lt;/em&gt; &lt;/span&gt; display a superscript. The &lt;em&gt;sidenote&lt;/em&gt; Liquid tag contains two components. The first is an identifier allowing the sidenote to be targeted by the twitchy index fingers of mobile device users so that all the yummy sidenote goodness is revealed when the superscript is tapped. The second components is the actual content of the sidenote. Both of these components should be enclosed in single quotes. Note that we are using the CSS ‘counter’ trick to automagically keep track of the number sequence on each page or post. On small screens, the sidenotes disappear and when the superscript is clicked, a side note will open below the content, which can then be closed with a similar click. Here is the markup for the sidenote at the beginning of this paragraph:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% sidenote 'sn-id-whatever' 'This is a sidenote and *displays a superscript*'%}&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;margin-notes&quot;&gt;Margin notes&lt;/h3&gt;

&lt;p&gt;Margin notes&lt;label for=&quot;mn-id-whatever&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mn-id-whatever&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;This is a margin note &lt;em&gt;without&lt;/em&gt; a superscript &lt;/span&gt; are similar to sidenotes, but do not display a superscript. The &lt;em&gt;marginnnote&lt;/em&gt; Liquid tags has the same two components as the &lt;em&gt;sidenote&lt;/em&gt; tag. Anything can be placed in a margin note. Well, anything that is an inline element. Block level elements can make the Kramdown parser do strange things. On small screens, the margin notes disappear and this symbol: &lt;span class=&quot;contrast &quot;&gt;⊕&lt;/span&gt; pops up. When clicked, it will open the margin note below the content, which can then be closed with a similar click. The Markdown content has a similar sort of markup as a sidenote, but without a number involved:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% marginnote 'mn-id-whatever' 'This is a margin note *without* a superscript' %}&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;equations&quot;&gt;Equations&lt;/h2&gt;

&lt;p&gt;The Markdown parser being used by this Jekyll theme is Kramdown, which contains some built-in &lt;a href=&quot;//www.mathjax.org&quot;&gt;Mathjax&lt;/a&gt; support. Both inline and block-level mathematical figures can be added to the content.&lt;/p&gt;

&lt;p&gt;For instance, the following inline sequence:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;When $$ a \ne 0 $$, there are two solutions to $$ ax^2 + bx + c = 0 $$&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;is written by enclosing a Mathjax expression within &lt;em&gt;a matching pair of double dollar signs: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$$&lt;/code&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;When $$ a \ne 0 $$, there are two solutions to $$ ax^2 + bx + c = 0 $$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Similarly, this block-level Mathjax expression:&lt;/p&gt;

&lt;p&gt;$$ x = {-b \pm \sqrt{b^2-4ac} \over 2a} $$&lt;/p&gt;

&lt;p&gt;is written by enclosing the expression within a pair of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$$&lt;/code&gt; with an empty line above and below:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$$ x = {-b \pm \sqrt{b^2-4ac} \over 2a} $$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;You can get pretty fancy, for instance, the wave equation’s nabla is no big thing:&lt;/p&gt;

&lt;p&gt;$$ \frac{\partial^2 y}{\partial t^2}= c^2\nabla^2u $$&lt;/p&gt;

&lt;p&gt;All of the standard &lt;span class=&quot;latex&quot;&gt;L&lt;sup&gt;a&lt;/sup&gt;T&lt;sub&gt;e&lt;/sub&gt;X&lt;/span&gt; equation markup is available to use inside these block tags.&lt;/p&gt;

&lt;p&gt;Please note that the block-level Mathjax expressions &lt;em&gt;must&lt;/em&gt; be on their own line, separated from content above and below the block by a blank line for the Kramdown parser and the Mathjax javascript to play nicely with one another.&lt;/p&gt;

&lt;p&gt;The Mathjax integration is tricky, and some things such as the inline matrix notation simply do not work well unless allowances are made for using the notation for a small matrix. Bottom line: If you are using this to document mathematics, be super careful to isolate your &lt;span class=&quot;latex&quot;&gt;L&lt;sup&gt;a&lt;/sup&gt;T&lt;sub&gt;e&lt;/sub&gt;X&lt;/span&gt; blocks by blank lines!&lt;/p&gt;

&lt;h2 id=&quot;tables&quot;&gt;Tables&lt;/h2&gt;

&lt;p&gt;Tables are, frankly,  a pain in the ass to create. That said, they often are one of the best methods for presenting data. Tabular data are normally presented with right-aligned numbers, left-aligned text, and minimal grid lines.&lt;/p&gt;

&lt;p&gt;Note that when writing Jekyll Markdown content, there will often be a need to get some dirt under your fingernails and stoop to writing a little honest-to-god html. Yes, all that hideous &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;table&amp;gt;..&amp;lt;thead&amp;gt;..&amp;lt;th&amp;gt;&lt;/code&gt; nonsense. &lt;em&gt;And&lt;/em&gt; you must wrap the unholy mess in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;div class=&quot;table-wrapper&quot;&amp;gt;&lt;/code&gt; tag to ensure that the table stays centered in the main content column.&lt;/p&gt;

&lt;p&gt;Tables are designed with an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;overflow:scroll&lt;/code&gt; property to create slider bars when the viewport is narrow. This is so that you do not collapse all your beautiful data into a jumble of letters and numbers when you view it on your smartphone.&lt;/p&gt;

&lt;p&gt;&lt;label for=&quot;table-1-id&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;table-1-id&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;em&gt;Table 1&lt;/em&gt;: A table with default style formatting &lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;table-wrapper&quot;&gt;
  &lt;table class=&quot;table-alpha&quot; id=&quot;newspaper-tone&quot;&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th class=&quot;left&quot;&gt;Content and tone of front-page articles in 94 U.S. newspapers, October and November, 1974&lt;/th&gt;
        &lt;th class=&quot;left&quot;&gt;Number of articles&lt;/th&gt;
        &lt;th&gt;Percent of articles with negative criticism of specific person or policy&lt;/th&gt;&lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td class=&quot;text&quot;&gt;Watergate: defendants and prosecutors, Ford’s pardon of Nixon&lt;/td&gt;
        &lt;td&gt;&lt;div class=&quot;number&quot;&gt;537&lt;/div&gt;&lt;/td&gt;
        &lt;td class=&quot;c&quot;&gt;&lt;div class=&quot;number&quot;&gt;49%&lt;/div&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td class=&quot;text&quot;&gt;Inflation, high cost of living&lt;/td&gt;
        &lt;td&gt;&lt;div class=&quot;number&quot;&gt;415&lt;/div&gt;&lt;/td&gt;
        &lt;td class=&quot;c&quot;&gt;&lt;div class=&quot;number&quot;&gt;28%&lt;/div&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td class=&quot;text&quot;&gt;Government competence: costs, quality, salaries of public employees&lt;/td&gt;
        &lt;td&gt;&lt;div class=&quot;number&quot;&gt;322&lt;/div&gt;&lt;/td&gt;
        &lt;td class=&quot;c&quot;&gt;&lt;div class=&quot;number&quot;&gt;30%&lt;/div&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td class=&quot;text&quot;&gt;Confidence in government: power of special interests, trust in political leaders, dishonesty in politics&lt;/td&gt;
        &lt;td&gt;&lt;div class=&quot;number&quot;&gt;266&lt;/div&gt;&lt;/td&gt;
        &lt;td class=&quot;c&quot;&gt;&lt;div class=&quot;number&quot;&gt;52%&lt;/div&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td class=&quot;text&quot;&gt;Government power: regulation of business, secrecy, control of CIA and FBI&lt;/td&gt;
        &lt;td&gt;&lt;div class=&quot;number&quot;&gt;154&lt;/div&gt;&lt;/td&gt;
        &lt;td class=&quot;c&quot;&gt;&lt;div class=&quot;number&quot;&gt;42%&lt;/div&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td class=&quot;text&quot;&gt;Crime&lt;/td&gt;
        &lt;td&gt;&lt;div class=&quot;number&quot;&gt;123&lt;/div&gt;&lt;/td&gt;
        &lt;td class=&quot;c&quot;&gt;&lt;div class=&quot;number r&quot;&gt;30%&lt;/div&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td class=&quot;text&quot;&gt;Race&lt;/td&gt;
        &lt;td&gt;&lt;div class=&quot;number&quot;&gt;103&lt;/div&gt;&lt;/td&gt;
        &lt;td class=&quot;c&quot;&gt;&lt;div class=&quot;number&quot;&gt;25%&lt;/div&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td class=&quot;text&quot;&gt;Unemployment&lt;/td&gt;
        &lt;td&gt;&lt;div class=&quot;number&quot;&gt;100&lt;/div&gt;&lt;/td&gt;
        &lt;td class=&quot;c&quot;&gt;&lt;div class=&quot;number&quot;&gt;13%&lt;/div&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td class=&quot;text&quot;&gt;Shortages: energy, food&lt;/td&gt;
        &lt;td&gt;&lt;div class=&quot;number&quot;&gt;68&lt;/div&gt;&lt;/td&gt;
        &lt;td class=&quot;c&quot;&gt;&lt;div class=&quot;number&quot;&gt;16%&lt;/div&gt;&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This is not the One True Table. Such a style does not exist. One must craft each data table with custom care to the narrative one is telling with that specific data. So take this not as “the table style to use”, but rather as “a table style to start from”. From here, use principles to guide you: avoid chartjunk, optimize the data-ink ratio (“within reason”, as Tufte says), and “mobilize every graphical element, perhaps several times over, to show the data.&lt;label for=&quot;table-id&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;table-id&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Page 139, &lt;em&gt;The Visual Display of Quantitative Information&lt;/em&gt;, Edward Tufte 2001. &lt;/span&gt; Furthermore, one must know when to reach for more complex data presentation tools, like a custom graphic or a JavaScript charting library.&lt;/p&gt;

&lt;p&gt;As an example of alternative table styles, academic publications written in &lt;span class=&quot;latex&quot;&gt;L&lt;sup&gt;a&lt;/sup&gt;T&lt;sub&gt;e&lt;/sub&gt;X&lt;/span&gt; often rely on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;booktabs&lt;/code&gt; package to produce clean, clear tables. Similar results can be achieved in Tufte CSS with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;booktabs&lt;/code&gt; class, as demonstrated in this table:&lt;/p&gt;

&lt;p&gt;&lt;label for=&quot;table-2-id&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;table-2-id&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;em&gt;Table 2&lt;/em&gt;: A table with booktabs style formatting &lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;table-wrapper&quot;&gt;
&lt;table class=&quot;booktabs&quot;&gt;
          &lt;thead&gt;
            &lt;tr&gt;&lt;th colspan=&quot;2&quot; class=&quot;cmid&quot;&gt;Items&lt;/th&gt;&lt;th class=&quot;nocmid&quot;&gt;&lt;/th&gt;&lt;/tr&gt;
            &lt;tr&gt;&lt;th class=&quot;l&quot;&gt;Animal&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;th class=&quot;r&quot;&gt;Price ($)&lt;/th&gt;&lt;/tr&gt;
          &lt;/thead&gt;
          &lt;tbody&gt;
            &lt;tr&gt;&lt;td&gt;Gnat&lt;/td&gt;     &lt;td&gt;per gram&lt;/td&gt;&lt;td class=&quot;r&quot;&gt;13.65&lt;/td&gt;&lt;/tr&gt;
            &lt;tr&gt;&lt;td&gt;&lt;/td&gt;         &lt;td&gt;each&lt;/td&gt;    &lt;td class=&quot;r&quot;&gt;0.01&lt;/td&gt;&lt;/tr&gt;
            &lt;tr&gt;&lt;td&gt;Gnu&lt;/td&gt;      &lt;td&gt;stuffed&lt;/td&gt; &lt;td class=&quot;r&quot;&gt;92.50&lt;/td&gt;&lt;/tr&gt;
            &lt;tr&gt;&lt;td&gt;Emu&lt;/td&gt;      &lt;td&gt;stuffed&lt;/td&gt; &lt;td class=&quot;r&quot;&gt;33.33&lt;/td&gt;&lt;/tr&gt;
            &lt;tr&gt;&lt;td&gt;Armadillo&lt;/td&gt;&lt;td&gt;frozen&lt;/td&gt;  &lt;td class=&quot;r&quot;&gt;8.99&lt;/td&gt;&lt;/tr&gt;
          &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The table above was written in HTML as follows:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;div class=&quot;table-wrapper&quot;&amp;gt;
&amp;lt;table class=&quot;booktabs&quot;&amp;gt;
          &amp;lt;thead&amp;gt;
            &amp;lt;tr&amp;gt;&amp;lt;th colspan=&quot;2&quot; class=&quot;cmid&quot;&amp;gt;Items&amp;lt;/th&amp;gt;&amp;lt;th class=&quot;nocmid&quot;&amp;gt;&amp;lt;/th&amp;gt;&amp;lt;/tr&amp;gt;
            &amp;lt;tr&amp;gt;&amp;lt;th class=&quot;l&quot;&amp;gt;Animal&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;Description&amp;lt;/th class=&quot;r&quot;&amp;gt;&amp;lt;th&amp;gt;Price ($)&amp;lt;/th&amp;gt;&amp;lt;/tr&amp;gt;
          &amp;lt;/thead&amp;gt;
          &amp;lt;tbody&amp;gt;
            &amp;lt;tr&amp;gt;&amp;lt;td&amp;gt;Gnat&amp;lt;/td&amp;gt;     &amp;lt;td&amp;gt;per gram&amp;lt;/td&amp;gt;&amp;lt;td class=&quot;r&quot;&amp;gt;13.65&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;
            &amp;lt;tr&amp;gt;&amp;lt;td&amp;gt;&amp;lt;/td&amp;gt;         &amp;lt;td&amp;gt;each&amp;lt;/td&amp;gt;    &amp;lt;td class=&quot;r&quot;&amp;gt;0.01&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;
            &amp;lt;tr&amp;gt;&amp;lt;td&amp;gt;Gnu&amp;lt;/td&amp;gt;      &amp;lt;td&amp;gt;stuffed&amp;lt;/td&amp;gt; &amp;lt;td class=&quot;r&quot;&amp;gt;92.50&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;
            &amp;lt;tr&amp;gt;&amp;lt;td&amp;gt;Emu&amp;lt;/td&amp;gt;      &amp;lt;td&amp;gt;stuffed&amp;lt;/td&amp;gt; &amp;lt;td class=&quot;r&quot;&amp;gt;33.33&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;
            &amp;lt;tr&amp;gt;&amp;lt;td&amp;gt;Armadillo&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;frozen&amp;lt;/td&amp;gt;  &amp;lt;td class=&quot;r&quot;&amp;gt;8.99&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;
          &amp;lt;/tbody&amp;gt;
&amp;lt;/table&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;span class=&quot;newthought&quot;&gt;I like this style of table,&lt;/span&gt;   so I have made it the default for unstyled tables. This allows use of the &lt;a href=&quot;https://michelf.ca/projects/php-markdown/extra/&quot;&gt;&lt;em&gt;Markdown Extra&lt;/em&gt;&lt;/a&gt; features built into the &lt;a href=&quot;http://kramdown.gettalong.org/parser/kramdown.html&quot;&gt;&lt;em&gt;Kramdown&lt;/em&gt;&lt;/a&gt; parser. Here is a table created using the Markdown Extra table syntax to make a nice table which has the side benefit of being human readable in the raw Markdown file:&lt;/p&gt;

&lt;p&gt;&lt;label for=&quot;tableID-3&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;tableID-3&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;Table 3: a table created with &lt;em&gt;Markdown Extra&lt;/em&gt; markup using only the default table styling &lt;/span&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;mpg&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;cyl&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;disp&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;hp&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;drat&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;wt&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Mazda RX4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;160&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;110&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.90&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.62&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Mazda RX4 Wag&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;160&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;110&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.90&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.88&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Datsun 710&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;22.8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;108&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;93&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.85&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Hornet 4 Drive&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21.4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;258&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;110&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.08&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.21&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Hornet Sportabout&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;18.7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;360&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;175&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.15&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.44&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Valiant&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;18.1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;160&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;105&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.76&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.46&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Using the following Markdown formatting:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;|                 |mpg  | cyl  |  disp  |   hp   |  drat  | wt  |
|:----------------|----:|-----:|-------:|-------:|-------:|----:|
|Mazda RX4        |21   |6     |160     |110     |3.90    |2.62 |
|Mazda RX4 Wag    |21   |6     |160     |110     |3.90    |2.88 |
|Datsun 710       |22.8 |4     |108     |93      |3.85    |2.32 |
etc...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following is a more simple table, showing the Markdown-style table markup. Remember to label the table with a &lt;em&gt;marginnote&lt;/em&gt; Liquid tag, and you &lt;em&gt;must&lt;/em&gt; separate the label from the table with a single blank line. This markup:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{% marginnote 'Table-ID4' 'Table 4: a simple table showing left, center, and right alignment of table headings and data'  %}

|**Left** |**Center**|**Right**|
|:--------|:--------:|--------:|
 Aardvarks|         1|$3.50
       Cat|   5      |$4.23
  Dogs    |3         |$5.29
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Yields this table:&lt;/p&gt;

&lt;p&gt;&lt;label for=&quot;Table-ID4&quot; class=&quot;margin-toggle&quot;&gt; ⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;Table-ID4&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;Table 4: a simple table showing left, center, and right alignment of table headings and data &lt;/span&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;**Left**&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;**Center**&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;**Right**&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Aardvarks&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$3.50&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Cat&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$4.23&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Dogs&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$5.29&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;

&lt;p&gt;Code samples use a monospace font using the ‘code’ class. The Kramdown parser has the ‘GFM’ option enabled, which stands for ‘Github Flavored Markdown’, and this means that both inline code such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#include &amp;lt;stdio.h&amp;gt;&lt;/code&gt; and blocks of code can be delimited by surrounding them with 3 backticks:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(map tufte-style all-the-things)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;is created by the following markup:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```(map tufte-style all-the-things)```&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To get the code highlighted in the language of your choice like so:&lt;/p&gt;

&lt;div class=&quot;language-ruby highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;Jekyll&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RenderFullWidthTag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Liquid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Tag&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;require&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;shellwords&quot;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;super&lt;/span&gt;
      &lt;span class=&quot;vi&quot;&gt;@text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;shellsplit&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;render&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;&amp;lt;div&amp;gt;&amp;lt;img class='fullwidth' src='&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;vi&quot;&gt;@text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;'/&amp;gt;&amp;lt;/div&amp;gt; &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;&amp;lt;p&amp;gt;&amp;lt;span class='marginnote'&amp;gt;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;vi&quot;&gt;@text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;Liquid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Template&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;register_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'fullwidth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Jekyll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;RenderFullWidthTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Enclose the code block in three backticks, followed by a space and then the language name, like this:&lt;/p&gt;

&lt;pre&gt; &lt;code&gt;``` ruby
    module Jekyll
    blah, blah...
   ```&lt;/code&gt; &lt;/pre&gt;

</description>
        <pubDate>Mon, 13 Apr 2020 05:46:04 -0400</pubDate>
        <link>/articles/20/tufte-style-jekyll-blog</link>
        <guid isPermaLink="true">/articles/20/tufte-style-jekyll-blog</guid>
        
        
        <category>jekyll</category>
        
        <category>css</category>
        
      </item>
    
  </channel>
</rss>
